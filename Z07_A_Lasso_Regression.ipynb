{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN_RZMP9-HjN"
      },
      "source": [
        "# Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "collapsed": true,
        "id": "7H1nhwyb-HjQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "import scipy.stats as stats\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9E0uYQu-HjS"
      },
      "source": [
        "Rozważmy następujący zbiór punktów:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "collapsed": true,
        "id": "xC1BfmQx-HjS"
      },
      "outputs": [],
      "source": [
        "true_fun = lambda X: np.cos(1.5 * np.pi * X)\n",
        "n_samples=20\n",
        "x = np.sort(np.random.rand(n_samples))\n",
        "y = true_fun(x) + np.random.randn(n_samples) * 0.1\n",
        "x=np.vstack(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3UQW2bP-HjT"
      },
      "source": [
        "# Przykład\n",
        "Proszę wykonać regresję (Ridge Regression) na powyższym zbiorze danych "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "s7XnGJyt-HjT",
        "outputId": "f4613672-97b8-4f57-beca-8bdef88ca792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "clf = Lasso(alpha=1.0)\n",
        "clf.fit(x, y) \n",
        "\n",
        "x_plot = np.vstack(np.linspace(0, 1, 20))\n",
        "plt.plot(x_plot, clf.predict(x_plot), color='blue',linewidth=3)\n",
        "plt.plot(x, y, 'ok');\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sREkxKzA-HjU"
      },
      "source": [
        "## Regresja liniowa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "AYY0pcRK-HjU",
        "outputId": "002e72e3-8b27-45c4-818d-a34861b240b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR degree 2\n",
            "LR degree 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# prepare models\n",
        "models = []\n",
        "predicts = []\n",
        "names=[]\n",
        "models.append(('LR degree 2', make_pipeline(PolynomialFeatures(2), linear_model.LinearRegression()) ))\n",
        "models.append(('LR degree 20', make_pipeline(PolynomialFeatures(20), linear_model.LinearRegression()) ))\n",
        "\n",
        "x_plot = np.vstack(np.linspace(-3, 3, 1000))\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    model.fit(x, y)\n",
        "    predicts.append(model.predict(x_plot))\n",
        "    names.append(name)\n",
        "    \n",
        "plt.plot(x, y, 'ok');\n",
        "for i in range(len(models)):\n",
        "    #print(i)\n",
        "    plt.plot(x_plot, predicts[i],linewidth=3,label=names[i])\n",
        "    plt.xlim((0, 1))\n",
        "    plt.ylim((-2, 2))\n",
        "plt.legend()    \n",
        "plt.show()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVSpPejk-HjV"
      },
      "source": [
        "# Zadanie \n",
        "Proszę wykonać \n",
        "* regresję dla wielomianów o stopniu **20**\n",
        "* regresję (Lasso Regression) dla wielomianów o stopniu **20** oraz\n",
        "   * alpha = 1 \n",
        "   * alpha = 10 000 \n",
        "   * alpha = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dYztjxjq-HjW",
        "outputId": "ee4aa209-c3a4-4bd1-eae2-1abf29694c86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso 1\n",
            "Lasso 10000\n",
            "Lasso 0.0001\n",
            "LR degree 2\n",
            "LR degree 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.682e-03, tolerance: 9.767e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# prepare models\n",
        "models = []\n",
        "predicts = []\n",
        "names=[]\n",
        "\n",
        "models.append(('Lasso 1', make_pipeline(PolynomialFeatures(20), Lasso(alpha=1)) ))\n",
        "models.append(('Lasso 10000', make_pipeline(PolynomialFeatures(20), Lasso(alpha=10000)) ))\n",
        "models.append(('Lasso 0.0001', make_pipeline(PolynomialFeatures(20), Lasso(alpha=0.0001)) ))\n",
        "\n",
        "models.append(('LR degree 2', make_pipeline(PolynomialFeatures(2), linear_model.LinearRegression()) ))\n",
        "models.append(('LR degree 20', make_pipeline(PolynomialFeatures(20), linear_model.LinearRegression()) ))\n",
        "\n",
        "x_plot = np.vstack(np.linspace(-3, 3, 1000))\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    model.fit(x, y)\n",
        "    predicts.append(model.predict(x_plot))\n",
        "    names.append(name)\n",
        "    \n",
        "plt.plot(x, y, 'ok');\n",
        "for i in range(len(models)):\n",
        "    #print(i)\n",
        "    plt.plot(x_plot, predicts[i],linewidth=3,label=names[i])\n",
        "    plt.xlim((0, 1))\n",
        "    plt.ylim((-2, 2))\n",
        "plt.legend()    \n",
        "plt.show()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7m1TdiQ-HjW"
      },
      "source": [
        "# Zdanie \n",
        "Dobierz optymalny stopień wielomianu oraz parametr alpha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "VCS-8d8G-HjW",
        "outputId": "1613ef38-f8f9-4295-a51b-721ece7f9c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.334e-02, tolerance: 3.320e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.182e-02, tolerance: 8.458e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.265e-02, tolerance: 9.085e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.271e-02, tolerance: 7.200e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.146e-03, tolerance: 8.821e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.881e-03, tolerance: 3.320e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.280e-03, tolerance: 8.458e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.090e-03, tolerance: 9.085e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.413e-03, tolerance: 7.200e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.409e-03, tolerance: 3.320e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e-03, tolerance: 8.458e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.544e-03, tolerance: 9.085e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.071e-02, tolerance: 7.200e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.491e-01, tolerance: 3.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.312e+00, tolerance: 8.458e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.054e+00, tolerance: 9.085e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.343e-01, tolerance: 8.821e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.627e-01, tolerance: 3.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.198e-01, tolerance: 8.458e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e-01, tolerance: 9.085e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.485e-01, tolerance: 7.200e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.387e-02, tolerance: 8.821e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.635e-02, tolerance: 3.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.671e-02, tolerance: 8.458e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.988e-02, tolerance: 9.085e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.103e-02, tolerance: 7.200e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.706e-02, tolerance: 8.821e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.289e-02, tolerance: 3.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.302e-02, tolerance: 8.458e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.628e-02, tolerance: 9.085e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.077e-02, tolerance: 7.200e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.806e-02, tolerance: 8.821e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.499e-02, tolerance: 3.320e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.367e-02, tolerance: 8.458e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.833e-02, tolerance: 9.085e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.262e-02, tolerance: 7.200e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.771e-02, tolerance: 8.821e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.283e-02, tolerance: 9.767e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lasso__alpha': 0, 'polynomialfeatures__degree': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "grid=GridSearchCV(make_pipeline(PolynomialFeatures(), linear_model.Lasso()),\n",
        "                  param_grid={'polynomialfeatures__degree': [1,2,3,4,5],\n",
        "                      'lasso__alpha': [0.0001,0.01, 0.1,0,1,10],},\n",
        "                  cv=model_selection.KFold(n_splits=5))\n",
        "grid.fit(x,y)\n",
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIv-5YjW-HjX"
      },
      "source": [
        "# Zdanie \n",
        "Dobierz optymalny stopień wielomianu oraz parametr <tt>alpha</tt> za pomocą metody <tt>GridSearchCV</tt> dla danych reklamowych, obejmującym sprzedaż produktów i ich budżet reklamowy w trzech różnych mediach telewizyjnych, radiu, gazetach.\n",
        "\n",
        "*  policz r_square score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "GPBHfQZb-HjX",
        "outputId": "7ec776be-97e2-470b-8841-28af20b97133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      TV  radio  newspaper  sales\n",
              "1  230.1   37.8       69.2   22.1\n",
              "2   44.5   39.3       45.1   10.4\n",
              "3   17.2   45.9       69.3    9.3\n",
              "4  151.5   41.3       58.5   18.5\n",
              "5  180.8   10.8       58.4   12.9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c433e96f-f52a-4a4f-a6b3-b3f01f3d61d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TV</th>\n",
              "      <th>radio</th>\n",
              "      <th>newspaper</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230.1</td>\n",
              "      <td>37.8</td>\n",
              "      <td>69.2</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44.5</td>\n",
              "      <td>39.3</td>\n",
              "      <td>45.1</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.2</td>\n",
              "      <td>45.9</td>\n",
              "      <td>69.3</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>151.5</td>\n",
              "      <td>41.3</td>\n",
              "      <td>58.5</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>180.8</td>\n",
              "      <td>10.8</td>\n",
              "      <td>58.4</td>\n",
              "      <td>12.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c433e96f-f52a-4a4f-a6b3-b3f01f3d61d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c433e96f-f52a-4a4f-a6b3-b3f01f3d61d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c433e96f-f52a-4a4f-a6b3-b3f01f3d61d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_adv = pd.read_csv('https://raw.githubusercontent.com/przem85/podstawy_sztucznej_inteligencji/main/Advertising.csv', index_col=0)\n",
        "X = df_adv[['TV', 'radio','newspaper']]\n",
        "y = df_adv['sales']\n",
        "df_adv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "1bSeY5LW-HjX",
        "outputId": "c5791f13-9698-41c2-fec4-9b54433346c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.865e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.902e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.988e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.857e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.768e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.907e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.038e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.824e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.714e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.895e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.060e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.969e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.037e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.996e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.181e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.226e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.172e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.019e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.933e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.099e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.157e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.983e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.879e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+02, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e+02, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+02, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+02, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+02, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.066e+01, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.058e+01, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e+01, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+01, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+01, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+01, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+01, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+01, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+01, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+01, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+01, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+01, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+01, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+01, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e+01, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+01, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+01, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+01, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+01, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.174e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.155e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.301e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.117e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.354e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.007e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.096e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.033e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.223e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.908e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.853e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.998e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.978e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.124e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.379e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.286e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.459e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.421e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.760e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.934e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.287e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.180e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.430e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.682e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.739e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.894e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.508e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.126e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+01, tolerance: 5.417e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9883578423514348"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "grid=GridSearchCV(make_pipeline(PolynomialFeatures(), linear_model.Lasso()),\n",
        "                  param_grid={\n",
        "                      'polynomialfeatures__degree': [1, 2, 3, 4, 5],\n",
        "                      'lasso__alpha': [0.0001, 0.01, 0.1, 0, 1, 10],\n",
        "                  },\n",
        "                  cv=model_selection.KFold(n_splits=5))\n",
        "grid.fit(X,y)\n",
        "grid.best_params_\n",
        "grid.best_score_"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Z07_A_Lasso_Regression.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}