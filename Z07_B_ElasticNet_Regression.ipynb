{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bi03RgOjFbwJ"
      },
      "source": [
        "# Lasso Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "auFaUcb3FbwO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model\n",
        "import scipy.stats as stats\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ7EARPhFbwQ"
      },
      "source": [
        "Rozważmy następujący zbiór punktów:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "id": "pwq8eYzwFbwQ"
      },
      "outputs": [],
      "source": [
        "true_fun = lambda X: np.cos(1.5 * np.pi * X)\n",
        "n_samples=20\n",
        "x = np.sort(np.random.rand(n_samples))\n",
        "y = true_fun(x) + np.random.randn(n_samples) * 0.1\n",
        "x=np.vstack(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K1bnF-4FbwR"
      },
      "source": [
        "# Przykład\n",
        "Proszę wykonać regresję (Ridge Regression) na powyższym zbiorze danych "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cB7r72ZkFbwS",
        "outputId": "5adbab2f-1973-4cca-a3c2-2412ecd0ec09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "clf = Lasso(alpha=1.0)\n",
        "clf.fit(x, y) \n",
        "\n",
        "x_plot = np.vstack(np.linspace(0, 1, 20))\n",
        "plt.plot(x_plot, clf.predict(x_plot), color='blue',linewidth=3)\n",
        "plt.plot(x, y, 'ok');\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9kDVoCDFbwT"
      },
      "source": [
        "## Regresja liniowa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xzmjGxj1FbwU",
        "outputId": "cc8b9094-ae35-4aa7-ba7d-91943ed2015c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR degree 2\n",
            "LR degree 20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# prepare models\n",
        "models = []\n",
        "predicts = []\n",
        "names=[]\n",
        "models.append(('LR degree 2', make_pipeline(PolynomialFeatures(2), linear_model.LinearRegression()) ))\n",
        "models.append(('LR degree 20', make_pipeline(PolynomialFeatures(20), linear_model.LinearRegression()) ))\n",
        "\n",
        "x_plot = np.vstack(np.linspace(-3, 3, 1000))\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    model.fit(x, y)\n",
        "    predicts.append(model.predict(x_plot))\n",
        "    names.append(name)\n",
        "    \n",
        "plt.plot(x, y, 'ok');\n",
        "for i in range(len(models)):\n",
        "    #print(i)\n",
        "    plt.plot(x_plot, predicts[i],linewidth=3,label=names[i])\n",
        "    plt.xlim((0, 1))\n",
        "    plt.ylim((-2, 2))\n",
        "plt.legend()    \n",
        "plt.show()    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYN_Q0fQFbwV"
      },
      "source": [
        "# Zadanie \n",
        "Proszę wykonać \n",
        "* regresję dla wielomianów o stopniu **20**\n",
        "* regresję (ElasticNet Regression) dla wielomianów o stopniu **20** oraz\n",
        "   * alpha = 1 \n",
        "   * alpha = 10 000 \n",
        "   * alpha = 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EuO77kbQFbwW",
        "outputId": "a6c5175f-a58f-4ba2-9254-e8d3c69189dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alpha 1\n",
            "alpha 10000\n",
            "alpha 0.001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.118e-02, tolerance: 6.250e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# prepare models\n",
        "models = []\n",
        "predicts = []\n",
        "names=[]\n",
        "models.append(('alpha 1', make_pipeline(PolynomialFeatures(20), ElasticNet(alpha=1)) ))\n",
        "models.append(('alpha 10000', make_pipeline(PolynomialFeatures(20), ElasticNet(alpha=10000)) ))\n",
        "models.append(('alpha 0.001', make_pipeline(PolynomialFeatures(20), ElasticNet(alpha=0.0001)) ))\n",
        "\n",
        "x_plot = np.vstack(np.linspace(-3, 3, 1000))\n",
        "for name, model in models:\n",
        "    print(name)\n",
        "    model.fit(x, y)\n",
        "    predicts.append(model.predict(x_plot))\n",
        "    names.append(name)\n",
        "    \n",
        "plt.plot(x, y, 'ok');\n",
        "for i in range(len(models)):\n",
        "    #print(i)\n",
        "    plt.plot(x_plot, predicts[i],linewidth=3,label=names[i])\n",
        "    plt.xlim((0, 1))\n",
        "    plt.ylim((-2, 2))\n",
        "plt.legend()    \n",
        "plt.show()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ywf0FM1FbwW"
      },
      "source": [
        "# Zdanie \n",
        "Dobierz optymalny stopień wielomianu oraz parametr alpha."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Crb4g0h8FbwW",
        "outputId": "f75c6180-8f2f-453d-dd50-0ff452b506bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.122e-03, tolerance: 2.041e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.874e-02, tolerance: 5.977e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.174e-02, tolerance: 5.170e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.599e-02, tolerance: 4.294e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.181e-03, tolerance: 6.082e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e-02, tolerance: 2.041e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.228e-02, tolerance: 5.977e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.938e-04, tolerance: 5.170e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.821e-02, tolerance: 4.294e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.145e-03, tolerance: 6.082e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.811e-02, tolerance: 2.041e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.738e-02, tolerance: 5.977e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.993e-02, tolerance: 5.170e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e-02, tolerance: 4.294e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.716e-04, tolerance: 6.082e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.538e-01, tolerance: 2.041e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+00, tolerance: 5.977e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.090e+00, tolerance: 5.170e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.305e+00, tolerance: 4.294e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.561e-01, tolerance: 6.082e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.774e-02, tolerance: 2.041e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.557e-01, tolerance: 5.977e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.387e-01, tolerance: 5.170e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.251e-01, tolerance: 4.294e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.126e-01, tolerance: 6.082e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.133e-02, tolerance: 2.041e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.163e-02, tolerance: 5.977e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.623e-02, tolerance: 5.170e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.085e-02, tolerance: 4.294e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.732e-02, tolerance: 6.082e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.987e-02, tolerance: 2.041e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.577e-02, tolerance: 5.977e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.092e-02, tolerance: 5.170e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.404e-02, tolerance: 4.294e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.854e-02, tolerance: 6.082e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.653e-02, tolerance: 2.041e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.457e-02, tolerance: 5.977e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.293e-02, tolerance: 5.170e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.808e-02, tolerance: 4.294e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.110e-02, tolerance: 6.082e-04 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.829e-02, tolerance: 6.250e-04\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'elasticnet__alpha': 0.0001, 'polynomialfeatures__degree': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "grid=GridSearchCV(make_pipeline(PolynomialFeatures(), linear_model.ElasticNet()),\n",
        "                  param_grid={'polynomialfeatures__degree': [1,2,3,4,5],\n",
        "                      'elasticnet__alpha': [0.0001,0.01, 0.1,0,1,10],},\n",
        "                  cv=model_selection.KFold(n_splits=5))\n",
        "grid.fit(x,y)\n",
        "grid.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nudp0pURFbwX"
      },
      "source": [
        "# Zdanie \n",
        "Dobierz optymalny stopień wielomianu oraz parametr <tt>alpha</tt> za pomocą metody <tt>GridSearchCV</tt> dla danych reklamowych, obejmującym sprzedaż produktów i ich budżet reklamowy w trzech różnych mediach telewizyjnych, radiu, gazetach.\n",
        "\n",
        "*  policz r_square score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FnzNhS-2FbwX",
        "outputId": "c0157ce3-c39b-4fc0-dd21-8c9a7aec7949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      TV  radio  newspaper  sales\n",
              "1  230.1   37.8       69.2   22.1\n",
              "2   44.5   39.3       45.1   10.4\n",
              "3   17.2   45.9       69.3    9.3\n",
              "4  151.5   41.3       58.5   18.5\n",
              "5  180.8   10.8       58.4   12.9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f4003f90-777f-4772-85d0-cc29dced22e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TV</th>\n",
              "      <th>radio</th>\n",
              "      <th>newspaper</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>230.1</td>\n",
              "      <td>37.8</td>\n",
              "      <td>69.2</td>\n",
              "      <td>22.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44.5</td>\n",
              "      <td>39.3</td>\n",
              "      <td>45.1</td>\n",
              "      <td>10.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>17.2</td>\n",
              "      <td>45.9</td>\n",
              "      <td>69.3</td>\n",
              "      <td>9.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>151.5</td>\n",
              "      <td>41.3</td>\n",
              "      <td>58.5</td>\n",
              "      <td>18.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>180.8</td>\n",
              "      <td>10.8</td>\n",
              "      <td>58.4</td>\n",
              "      <td>12.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f4003f90-777f-4772-85d0-cc29dced22e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f4003f90-777f-4772-85d0-cc29dced22e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f4003f90-777f-4772-85d0-cc29dced22e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_adv = pd.read_csv('https://raw.githubusercontent.com/przem85/podstawy_sztucznej_inteligencji/main/Advertising.csv', index_col=0)\n",
        "X = df_adv[['TV', 'radio','newspaper']]\n",
        "y = df_adv['sales']\n",
        "df_adv.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QNt1URmAFbwY",
        "outputId": "70ad0495-4160-40c5-b687-ff0aae0051bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.957e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.888e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.849e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.973e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.025e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.844e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.892e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.028e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.979e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.811e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.702e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.881e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.981e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.934e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.102e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.121e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.949e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.852e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.013e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.117e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.082e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.918e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.800e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.145e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.055e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.169e+02, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.312e+02, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.484e+02, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+02, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.257e+02, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.066e+01, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.058e+01, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e+01, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.576e+01, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.370e+01, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.873e+01, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.836e+01, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.956e+01, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.037e+01, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.011e+01, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+01, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.744e+01, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.876e+01, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.017e+01, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.965e+01, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.796e+01, tolerance: 4.383e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.689e+01, tolerance: 4.218e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.864e+01, tolerance: 4.503e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.034e+01, tolerance: 4.199e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py:394: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
            "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+01, tolerance: 4.348e-01 Linear regression models with null weight for the l1 regularization term are more efficiently fitted using one of the solvers implemented in sklearn.linear_model.Ridge/RidgeCV instead.\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.594e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.550e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.658e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.743e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.513e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.600e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.607e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.692e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.457e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.377e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.534e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.599e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.632e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.205e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.392e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.408e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.232e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.664e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.911e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.259e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.998e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.745e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.320e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.520e+01, tolerance: 4.383e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.567e+01, tolerance: 4.218e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.681e+01, tolerance: 4.503e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.339e+01, tolerance: 4.199e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.910e+01, tolerance: 4.348e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.399e+01, tolerance: 5.417e-01\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9881072588784162"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "grid=GridSearchCV(make_pipeline(PolynomialFeatures(), linear_model.ElasticNet()),\n",
        "                  param_grid={\n",
        "                      'polynomialfeatures__degree': [1, 2, 3, 4, 5],\n",
        "                      'elasticnet__alpha': [0.0001, 0.01, 0.1, 0, 1, 10],\n",
        "                  },\n",
        "                  cv=model_selection.KFold(n_splits=5))\n",
        "grid.fit(X,y)\n",
        "grid.best_params_\n",
        "grid.best_score_"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Z07_B_ElasticNet_Regression.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}